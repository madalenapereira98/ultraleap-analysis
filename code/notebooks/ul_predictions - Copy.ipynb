{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import public packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import math\n",
    "import statistics as stat\n",
    "import json\n",
    "from scipy import interp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Cross Validation Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut, LeaveOneGroupOut\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classifiers and Feature Selection Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import metrics\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_path_in_notebook():\n",
    "    \"\"\"\n",
    "    Finds path of repo from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "    repo_name = 'ultraleap_analysis'\n",
    "\n",
    "    while path[-len(repo_name):] != 'ultraleap_analysis':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = get_repo_path_in_notebook()\n",
    "code_path = os.path.join(repo_path, 'code')\n",
    "os.chdir(code_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import own functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sig_processing.extract_scores as sc_ext\n",
    "import sig_processing.predict as pred\n",
    "import plotting.boxplotting as bxplt\n",
    "import statistic.stat_analysis as statis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading features (X) and scores (y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load features from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# define task\n",
    "folder = 'patientdata'\n",
    "task = 'ft'\n",
    "feat_file = 'features'\n",
    "# feat_file = 'features'\n",
    "\n",
    "\n",
    "feat_df_path = os.path.join(\n",
    "    repo_path,\n",
    "    'EDA',\n",
    "    folder,\n",
    "    task, \n",
    "    f'{feat_file}.csv'\n",
    "    )\n",
    "\n",
    "X_df = pd.read_csv(feat_df_path, index_col=0)\n",
    "feat_cols = X_df.iloc[:,1:].columns\n",
    "print(len(feat_cols))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load scores/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No scores for block ('b1', 'ul020', 'm1s1', 'dt', 'ft', 'lh') or this combination does not exist\n",
      "No scores for block ('b2', 'ul020', 'm1s1', 'dt', 'ft', 'lh') or this combination does not exist\n",
      "No scores for block ('b3', 'ul020', 'm1s1', 'dt', 'ft', 'lh') or this combination does not exist\n"
     ]
    }
   ],
   "source": [
    "y_with_nan = sc_ext.get_labels_for_feat_df(X_df)\n",
    "y = np.array([i for i in y_with_nan if not np.isnan(i)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non-scored/non-existing rows/blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>num_events</th>\n",
       "      <th>mean_max_dist</th>\n",
       "      <th>sd_max_dist</th>\n",
       "      <th>coef_var_max_dist</th>\n",
       "      <th>slope_max_dist</th>\n",
       "      <th>decr_max_dist</th>\n",
       "      <th>max_open_vel</th>\n",
       "      <th>mean_open_vel</th>\n",
       "      <th>sd_open_vel</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_tap_dur</th>\n",
       "      <th>sd_tap_dur</th>\n",
       "      <th>coef_var_tap_dur</th>\n",
       "      <th>slope_tap_dur</th>\n",
       "      <th>mean_rms</th>\n",
       "      <th>sd_rms</th>\n",
       "      <th>slope_rms</th>\n",
       "      <th>sum_rms</th>\n",
       "      <th>jerkiness</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1_ul001_m1_vr_ft_right.json</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.139815</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>0.043111</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>1.480322</td>\n",
       "      <td>0.887650</td>\n",
       "      <td>0.298676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419996</td>\n",
       "      <td>0.143758</td>\n",
       "      <td>0.342284</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>1.839024</td>\n",
       "      <td>10.092632</td>\n",
       "      <td>6.683361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2_ul001_m1_vr_ft_right.json</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.134651</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.031957</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.021412</td>\n",
       "      <td>1.335573</td>\n",
       "      <td>0.955032</td>\n",
       "      <td>0.209491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360834</td>\n",
       "      <td>0.031273</td>\n",
       "      <td>0.086668</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.077003</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>2.387097</td>\n",
       "      <td>7.849825</td>\n",
       "      <td>6.683361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b1_ul001_m1_dt_ft_right.json</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.085116</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.228008</td>\n",
       "      <td>-0.001458</td>\n",
       "      <td>-0.319352</td>\n",
       "      <td>0.789643</td>\n",
       "      <td>0.450597</td>\n",
       "      <td>0.181050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485763</td>\n",
       "      <td>0.091018</td>\n",
       "      <td>0.187371</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>0.050737</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>1.014738</td>\n",
       "      <td>11.774737</td>\n",
       "      <td>6.683361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2_ul001_m1_dt_ft_right.json</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.085684</td>\n",
       "      <td>0.016888</td>\n",
       "      <td>0.197097</td>\n",
       "      <td>-0.001391</td>\n",
       "      <td>-0.185258</td>\n",
       "      <td>0.832657</td>\n",
       "      <td>0.438804</td>\n",
       "      <td>0.196246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435584</td>\n",
       "      <td>0.092162</td>\n",
       "      <td>0.211582</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.049935</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>1.298314</td>\n",
       "      <td>11.029105</td>\n",
       "      <td>6.673298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b3_ul001_m1_dt_ft_right.json</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>0.010456</td>\n",
       "      <td>0.104615</td>\n",
       "      <td>-0.000799</td>\n",
       "      <td>-0.153763</td>\n",
       "      <td>1.697059</td>\n",
       "      <td>0.388181</td>\n",
       "      <td>0.312169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425662</td>\n",
       "      <td>0.081414</td>\n",
       "      <td>0.191265</td>\n",
       "      <td>-0.002156</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>1.423192</td>\n",
       "      <td>10.973734</td>\n",
       "      <td>6.681626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>b3_ul019_m0s0_dt_ft_left.json</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.044174</td>\n",
       "      <td>0.008587</td>\n",
       "      <td>0.194383</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.355184</td>\n",
       "      <td>0.268989</td>\n",
       "      <td>0.139823</td>\n",
       "      <td>0.070897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438048</td>\n",
       "      <td>0.095590</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.028188</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.253693</td>\n",
       "      <td>6.500339</td>\n",
       "      <td>6.643790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>b1_ul019_m1s0_vr_ft_left.json</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.022558</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>0.166116</td>\n",
       "      <td>-0.003189</td>\n",
       "      <td>-0.316802</td>\n",
       "      <td>0.084076</td>\n",
       "      <td>0.047405</td>\n",
       "      <td>0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>1.338665</td>\n",
       "      <td>0.629601</td>\n",
       "      <td>0.470320</td>\n",
       "      <td>0.514604</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>-0.001221</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>9.305886</td>\n",
       "      <td>6.572608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>b3_ul019_m1s0_vr_ft_left.json</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.025528</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>0.231810</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.419691</td>\n",
       "      <td>0.212031</td>\n",
       "      <td>0.125182</td>\n",
       "      <td>0.039923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473485</td>\n",
       "      <td>0.123695</td>\n",
       "      <td>0.261243</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.277265</td>\n",
       "      <td>6.648331</td>\n",
       "      <td>6.682109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>b2_ul019_m1s1_vr_ft_left.json</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.126682</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.286117</td>\n",
       "      <td>0.141156</td>\n",
       "      <td>0.076096</td>\n",
       "      <td>0.062999</td>\n",
       "      <td>...</td>\n",
       "      <td>1.950188</td>\n",
       "      <td>1.797032</td>\n",
       "      <td>0.921466</td>\n",
       "      <td>0.708020</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>7.048833</td>\n",
       "      <td>6.678634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>b3_ul019_m0s1_dt_ft_left.json</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.041833</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.149744</td>\n",
       "      <td>-0.003160</td>\n",
       "      <td>-0.198649</td>\n",
       "      <td>0.072899</td>\n",
       "      <td>0.050294</td>\n",
       "      <td>0.017606</td>\n",
       "      <td>...</td>\n",
       "      <td>2.232267</td>\n",
       "      <td>1.091960</td>\n",
       "      <td>0.489171</td>\n",
       "      <td>0.248609</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>-0.002045</td>\n",
       "      <td>0.146685</td>\n",
       "      <td>10.174150</td>\n",
       "      <td>6.577861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file  num_events  mean_max_dist  sd_max_dist  \\\n",
       "0     b1_ul001_m1_vr_ft_right.json        26.0       0.139815     0.006028   \n",
       "1     b2_ul001_m1_vr_ft_right.json        31.0       0.134651     0.004303   \n",
       "2     b1_ul001_m1_dt_ft_right.json        20.0       0.085116     0.019407   \n",
       "3     b2_ul001_m1_dt_ft_right.json        26.0       0.085684     0.016888   \n",
       "4     b3_ul001_m1_dt_ft_right.json        24.0       0.099948     0.010456   \n",
       "..                             ...         ...            ...          ...   \n",
       "195  b3_ul019_m0s0_dt_ft_left.json         9.0       0.044174     0.008587   \n",
       "196  b1_ul019_m1s0_vr_ft_left.json         4.0       0.022558     0.003747   \n",
       "197  b3_ul019_m1s0_vr_ft_left.json        22.0       0.025528     0.005918   \n",
       "198  b2_ul019_m1s1_vr_ft_left.json         4.0       0.022242     0.002818   \n",
       "199  b3_ul019_m0s1_dt_ft_left.json         5.0       0.041833     0.006264   \n",
       "\n",
       "     coef_var_max_dist  slope_max_dist  decr_max_dist  max_open_vel  \\\n",
       "0             0.043111       -0.000533       0.004762      1.480322   \n",
       "1             0.031957        0.000012      -0.021412      1.335573   \n",
       "2             0.228008       -0.001458      -0.319352      0.789643   \n",
       "3             0.197097       -0.001391      -0.185258      0.832657   \n",
       "4             0.104615       -0.000799      -0.153763      1.697059   \n",
       "..                 ...             ...            ...           ...   \n",
       "195           0.194383       -0.000580      -0.355184      0.268989   \n",
       "196           0.166116       -0.003189      -0.316802      0.084076   \n",
       "197           0.231810       -0.000124      -0.419691      0.212031   \n",
       "198           0.126682        0.001845       0.286117      0.141156   \n",
       "199           0.149744       -0.003160      -0.198649      0.072899   \n",
       "\n",
       "     mean_open_vel  sd_open_vel  ...  mean_tap_dur  sd_tap_dur  \\\n",
       "0         0.887650     0.298676  ...      0.419996    0.143758   \n",
       "1         0.955032     0.209491  ...      0.360834    0.031273   \n",
       "2         0.450597     0.181050  ...      0.485763    0.091018   \n",
       "3         0.438804     0.196246  ...      0.435584    0.092162   \n",
       "4         0.388181     0.312169  ...      0.425662    0.081414   \n",
       "..             ...          ...  ...           ...         ...   \n",
       "195       0.139823     0.070897  ...      0.438048    0.095590   \n",
       "196       0.047405     0.029834  ...      1.338665    0.629601   \n",
       "197       0.125182     0.039923  ...      0.473485    0.123695   \n",
       "198       0.076096     0.062999  ...      1.950188    1.797032   \n",
       "199       0.050294     0.017606  ...      2.232267    1.091960   \n",
       "\n",
       "     coef_var_tap_dur  slope_tap_dur  mean_rms    sd_rms  slope_rms   sum_rms  \\\n",
       "0            0.342284       0.002407  0.070732  0.007275  -0.000468  1.839024   \n",
       "1            0.086668      -0.000461  0.077003  0.005023  -0.000076  2.387097   \n",
       "2            0.187371      -0.000741  0.050737  0.006412  -0.000528  1.014738   \n",
       "3            0.211582       0.006528  0.049935  0.007470  -0.000400  1.298314   \n",
       "4            0.191265      -0.002156  0.059300  0.004795  -0.000207  1.423192   \n",
       "..                ...            ...       ...       ...        ...       ...   \n",
       "195          0.218218       0.002086  0.028188  0.005371   0.001271  0.253693   \n",
       "196          0.470320       0.514604  0.009906  0.001527  -0.001221  0.039626   \n",
       "197          0.261243       0.001424  0.012603  0.002452   0.000065  0.277265   \n",
       "198          0.921466       0.708020  0.009495  0.001056   0.000741  0.037981   \n",
       "199          0.489171       0.248609  0.029337  0.003224  -0.002045  0.146685   \n",
       "\n",
       "     jerkiness   entropy  \n",
       "0    10.092632  6.683361  \n",
       "1     7.849825  6.683361  \n",
       "2    11.774737  6.683361  \n",
       "3    11.029105  6.673298  \n",
       "4    10.973734  6.681626  \n",
       "..         ...       ...  \n",
       "195   6.500339  6.643790  \n",
       "196   9.305886  6.572608  \n",
       "197   6.648331  6.682109  \n",
       "198   7.048833  6.678634  \n",
       "199  10.174150  6.577861  \n",
       "\n",
       "[200 rows x 27 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    X_df = sc_ext.remove_non_score_rows(X_df, y_with_nan)\n",
    "except KeyError:\n",
    "    print('Non-scored/non-existing rows/blocks have already been scored.')\n",
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create group encoder for leave one group out cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group encoder for leave one group out cross validation\n",
    "groups = [X_df['file'].iloc[row][3:8] for row in np.arange(0, X_df.shape[0])]\n",
    "group_encoder = LabelEncoder()\n",
    "group_int = group_encoder.fit_transform(groups)\n",
    "\n",
    "# Alternative method to encode the groups\n",
    "# group_encoder = {group: i for i, group in enumerate(np.unique(groups))}\n",
    "# group_int = np.array([group_encoder[group] for group in groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>num_events</th>\n",
       "      <th>mean_max_dist</th>\n",
       "      <th>sd_max_dist</th>\n",
       "      <th>coef_var_max_dist</th>\n",
       "      <th>slope_max_dist</th>\n",
       "      <th>decr_max_dist</th>\n",
       "      <th>max_open_vel</th>\n",
       "      <th>mean_open_vel</th>\n",
       "      <th>sd_open_vel</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_tap_dur</th>\n",
       "      <th>sd_tap_dur</th>\n",
       "      <th>coef_var_tap_dur</th>\n",
       "      <th>slope_tap_dur</th>\n",
       "      <th>mean_rms</th>\n",
       "      <th>sd_rms</th>\n",
       "      <th>slope_rms</th>\n",
       "      <th>sum_rms</th>\n",
       "      <th>jerkiness</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1_ul001_m1_vr_ft_right.json</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.139815</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>0.043111</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>1.480322</td>\n",
       "      <td>0.887650</td>\n",
       "      <td>0.298676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419996</td>\n",
       "      <td>0.143758</td>\n",
       "      <td>0.342284</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>1.839024</td>\n",
       "      <td>10.092632</td>\n",
       "      <td>6.683361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2_ul001_m1_vr_ft_right.json</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.134651</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.031957</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.021412</td>\n",
       "      <td>1.335573</td>\n",
       "      <td>0.955032</td>\n",
       "      <td>0.209491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360834</td>\n",
       "      <td>0.031273</td>\n",
       "      <td>0.086668</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.077003</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>2.387097</td>\n",
       "      <td>7.849825</td>\n",
       "      <td>6.683361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b1_ul001_m1_dt_ft_right.json</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.085116</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.228008</td>\n",
       "      <td>-0.001458</td>\n",
       "      <td>-0.319352</td>\n",
       "      <td>0.789643</td>\n",
       "      <td>0.450597</td>\n",
       "      <td>0.181050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485763</td>\n",
       "      <td>0.091018</td>\n",
       "      <td>0.187371</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>0.050737</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>1.014738</td>\n",
       "      <td>11.774737</td>\n",
       "      <td>6.683361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2_ul001_m1_dt_ft_right.json</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.085684</td>\n",
       "      <td>0.016888</td>\n",
       "      <td>0.197097</td>\n",
       "      <td>-0.001391</td>\n",
       "      <td>-0.185258</td>\n",
       "      <td>0.832657</td>\n",
       "      <td>0.438804</td>\n",
       "      <td>0.196246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435584</td>\n",
       "      <td>0.092162</td>\n",
       "      <td>0.211582</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.049935</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>1.298314</td>\n",
       "      <td>11.029105</td>\n",
       "      <td>6.673298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b3_ul001_m1_dt_ft_right.json</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>0.010456</td>\n",
       "      <td>0.104615</td>\n",
       "      <td>-0.000799</td>\n",
       "      <td>-0.153763</td>\n",
       "      <td>1.697059</td>\n",
       "      <td>0.388181</td>\n",
       "      <td>0.312169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425662</td>\n",
       "      <td>0.081414</td>\n",
       "      <td>0.191265</td>\n",
       "      <td>-0.002156</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>1.423192</td>\n",
       "      <td>10.973734</td>\n",
       "      <td>6.681626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>b3_ul019_m0s0_dt_ft_left.json</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.044174</td>\n",
       "      <td>0.008587</td>\n",
       "      <td>0.194383</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.355184</td>\n",
       "      <td>0.268989</td>\n",
       "      <td>0.139823</td>\n",
       "      <td>0.070897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438048</td>\n",
       "      <td>0.095590</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.028188</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.253693</td>\n",
       "      <td>6.500339</td>\n",
       "      <td>6.643790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>b1_ul019_m1s0_vr_ft_left.json</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.022558</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>0.166116</td>\n",
       "      <td>-0.003189</td>\n",
       "      <td>-0.316802</td>\n",
       "      <td>0.084076</td>\n",
       "      <td>0.047405</td>\n",
       "      <td>0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>1.338665</td>\n",
       "      <td>0.629601</td>\n",
       "      <td>0.470320</td>\n",
       "      <td>0.514604</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>-0.001221</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>9.305886</td>\n",
       "      <td>6.572608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>b3_ul019_m1s0_vr_ft_left.json</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.025528</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>0.231810</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.419691</td>\n",
       "      <td>0.212031</td>\n",
       "      <td>0.125182</td>\n",
       "      <td>0.039923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473485</td>\n",
       "      <td>0.123695</td>\n",
       "      <td>0.261243</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.277265</td>\n",
       "      <td>6.648331</td>\n",
       "      <td>6.682109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>b2_ul019_m1s1_vr_ft_left.json</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.126682</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.286117</td>\n",
       "      <td>0.141156</td>\n",
       "      <td>0.076096</td>\n",
       "      <td>0.062999</td>\n",
       "      <td>...</td>\n",
       "      <td>1.950188</td>\n",
       "      <td>1.797032</td>\n",
       "      <td>0.921466</td>\n",
       "      <td>0.708020</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>7.048833</td>\n",
       "      <td>6.678634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>b3_ul019_m0s1_dt_ft_left.json</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.041833</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.149744</td>\n",
       "      <td>-0.003160</td>\n",
       "      <td>-0.198649</td>\n",
       "      <td>0.072899</td>\n",
       "      <td>0.050294</td>\n",
       "      <td>0.017606</td>\n",
       "      <td>...</td>\n",
       "      <td>2.232267</td>\n",
       "      <td>1.091960</td>\n",
       "      <td>0.489171</td>\n",
       "      <td>0.248609</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>-0.002045</td>\n",
       "      <td>0.146685</td>\n",
       "      <td>10.174150</td>\n",
       "      <td>6.577861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file  num_events  mean_max_dist  sd_max_dist  \\\n",
       "0     b1_ul001_m1_vr_ft_right.json        26.0       0.139815     0.006028   \n",
       "1     b2_ul001_m1_vr_ft_right.json        31.0       0.134651     0.004303   \n",
       "2     b1_ul001_m1_dt_ft_right.json        20.0       0.085116     0.019407   \n",
       "3     b2_ul001_m1_dt_ft_right.json        26.0       0.085684     0.016888   \n",
       "4     b3_ul001_m1_dt_ft_right.json        24.0       0.099948     0.010456   \n",
       "..                             ...         ...            ...          ...   \n",
       "195  b3_ul019_m0s0_dt_ft_left.json         9.0       0.044174     0.008587   \n",
       "196  b1_ul019_m1s0_vr_ft_left.json         4.0       0.022558     0.003747   \n",
       "197  b3_ul019_m1s0_vr_ft_left.json        22.0       0.025528     0.005918   \n",
       "198  b2_ul019_m1s1_vr_ft_left.json         4.0       0.022242     0.002818   \n",
       "199  b3_ul019_m0s1_dt_ft_left.json         5.0       0.041833     0.006264   \n",
       "\n",
       "     coef_var_max_dist  slope_max_dist  decr_max_dist  max_open_vel  \\\n",
       "0             0.043111       -0.000533       0.004762      1.480322   \n",
       "1             0.031957        0.000012      -0.021412      1.335573   \n",
       "2             0.228008       -0.001458      -0.319352      0.789643   \n",
       "3             0.197097       -0.001391      -0.185258      0.832657   \n",
       "4             0.104615       -0.000799      -0.153763      1.697059   \n",
       "..                 ...             ...            ...           ...   \n",
       "195           0.194383       -0.000580      -0.355184      0.268989   \n",
       "196           0.166116       -0.003189      -0.316802      0.084076   \n",
       "197           0.231810       -0.000124      -0.419691      0.212031   \n",
       "198           0.126682        0.001845       0.286117      0.141156   \n",
       "199           0.149744       -0.003160      -0.198649      0.072899   \n",
       "\n",
       "     mean_open_vel  sd_open_vel  ...  mean_tap_dur  sd_tap_dur  \\\n",
       "0         0.887650     0.298676  ...      0.419996    0.143758   \n",
       "1         0.955032     0.209491  ...      0.360834    0.031273   \n",
       "2         0.450597     0.181050  ...      0.485763    0.091018   \n",
       "3         0.438804     0.196246  ...      0.435584    0.092162   \n",
       "4         0.388181     0.312169  ...      0.425662    0.081414   \n",
       "..             ...          ...  ...           ...         ...   \n",
       "195       0.139823     0.070897  ...      0.438048    0.095590   \n",
       "196       0.047405     0.029834  ...      1.338665    0.629601   \n",
       "197       0.125182     0.039923  ...      0.473485    0.123695   \n",
       "198       0.076096     0.062999  ...      1.950188    1.797032   \n",
       "199       0.050294     0.017606  ...      2.232267    1.091960   \n",
       "\n",
       "     coef_var_tap_dur  slope_tap_dur  mean_rms    sd_rms  slope_rms   sum_rms  \\\n",
       "0            0.342284       0.002407  0.070732  0.007275  -0.000468  1.839024   \n",
       "1            0.086668      -0.000461  0.077003  0.005023  -0.000076  2.387097   \n",
       "2            0.187371      -0.000741  0.050737  0.006412  -0.000528  1.014738   \n",
       "3            0.211582       0.006528  0.049935  0.007470  -0.000400  1.298314   \n",
       "4            0.191265      -0.002156  0.059300  0.004795  -0.000207  1.423192   \n",
       "..                ...            ...       ...       ...        ...       ...   \n",
       "195          0.218218       0.002086  0.028188  0.005371   0.001271  0.253693   \n",
       "196          0.470320       0.514604  0.009906  0.001527  -0.001221  0.039626   \n",
       "197          0.261243       0.001424  0.012603  0.002452   0.000065  0.277265   \n",
       "198          0.921466       0.708020  0.009495  0.001056   0.000741  0.037981   \n",
       "199          0.489171       0.248609  0.029337  0.003224  -0.002045  0.146685   \n",
       "\n",
       "     jerkiness   entropy  \n",
       "0    10.092632  6.683361  \n",
       "1     7.849825  6.683361  \n",
       "2    11.774737  6.683361  \n",
       "3    11.029105  6.673298  \n",
       "4    10.973734  6.681626  \n",
       "..         ...       ...  \n",
       "195   6.500339  6.643790  \n",
       "196   9.305886  6.572608  \n",
       "197   6.648331  6.682109  \n",
       "198   7.048833  6.678634  \n",
       "199  10.174150  6.577861  \n",
       "\n",
       "[200 rows x 27 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling - Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_events</th>\n",
       "      <th>mean_max_dist</th>\n",
       "      <th>sd_max_dist</th>\n",
       "      <th>coef_var_max_dist</th>\n",
       "      <th>slope_max_dist</th>\n",
       "      <th>decr_max_dist</th>\n",
       "      <th>max_open_vel</th>\n",
       "      <th>mean_open_vel</th>\n",
       "      <th>sd_open_vel</th>\n",
       "      <th>coef_var_open_vel</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_tap_dur</th>\n",
       "      <th>sd_tap_dur</th>\n",
       "      <th>coef_var_tap_dur</th>\n",
       "      <th>slope_tap_dur</th>\n",
       "      <th>mean_rms</th>\n",
       "      <th>sd_rms</th>\n",
       "      <th>slope_rms</th>\n",
       "      <th>sum_rms</th>\n",
       "      <th>jerkiness</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.959942</td>\n",
       "      <td>0.240231</td>\n",
       "      <td>0.050978</td>\n",
       "      <td>0.619832</td>\n",
       "      <td>0.194640</td>\n",
       "      <td>0.870151</td>\n",
       "      <td>0.927892</td>\n",
       "      <td>0.956073</td>\n",
       "      <td>0.197846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045689</td>\n",
       "      <td>0.062263</td>\n",
       "      <td>0.243113</td>\n",
       "      <td>0.713026</td>\n",
       "      <td>0.725267</td>\n",
       "      <td>0.502424</td>\n",
       "      <td>0.582741</td>\n",
       "      <td>0.705809</td>\n",
       "      <td>0.357179</td>\n",
       "      <td>0.648389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.920167</td>\n",
       "      <td>0.154030</td>\n",
       "      <td>0.026472</td>\n",
       "      <td>0.656287</td>\n",
       "      <td>0.187525</td>\n",
       "      <td>0.783431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665735</td>\n",
       "      <td>0.094380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024181</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.028440</td>\n",
       "      <td>0.711860</td>\n",
       "      <td>0.798303</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.628076</td>\n",
       "      <td>0.919098</td>\n",
       "      <td>0.239462</td>\n",
       "      <td>0.648389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.538621</td>\n",
       "      <td>0.908983</td>\n",
       "      <td>0.457181</td>\n",
       "      <td>0.557987</td>\n",
       "      <td>0.106533</td>\n",
       "      <td>0.456361</td>\n",
       "      <td>0.460181</td>\n",
       "      <td>0.573146</td>\n",
       "      <td>0.255551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069597</td>\n",
       "      <td>0.036218</td>\n",
       "      <td>0.113013</td>\n",
       "      <td>0.711745</td>\n",
       "      <td>0.492411</td>\n",
       "      <td>0.432710</td>\n",
       "      <td>0.575695</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>0.445467</td>\n",
       "      <td>0.648389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.542995</td>\n",
       "      <td>0.783069</td>\n",
       "      <td>0.389272</td>\n",
       "      <td>0.562479</td>\n",
       "      <td>0.142985</td>\n",
       "      <td>0.482131</td>\n",
       "      <td>0.447561</td>\n",
       "      <td>0.622616</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051355</td>\n",
       "      <td>0.036783</td>\n",
       "      <td>0.133346</td>\n",
       "      <td>0.714702</td>\n",
       "      <td>0.483074</td>\n",
       "      <td>0.518201</td>\n",
       "      <td>0.590592</td>\n",
       "      <td>0.495385</td>\n",
       "      <td>0.406332</td>\n",
       "      <td>0.639671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.652869</td>\n",
       "      <td>0.461581</td>\n",
       "      <td>0.186096</td>\n",
       "      <td>0.602020</td>\n",
       "      <td>0.151547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.393386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.611015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047748</td>\n",
       "      <td>0.031475</td>\n",
       "      <td>0.116283</td>\n",
       "      <td>0.711170</td>\n",
       "      <td>0.592132</td>\n",
       "      <td>0.302044</td>\n",
       "      <td>0.612841</td>\n",
       "      <td>0.543983</td>\n",
       "      <td>0.403425</td>\n",
       "      <td>0.646886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.223260</td>\n",
       "      <td>0.368141</td>\n",
       "      <td>0.383310</td>\n",
       "      <td>0.616676</td>\n",
       "      <td>0.096793</td>\n",
       "      <td>0.144433</td>\n",
       "      <td>0.127607</td>\n",
       "      <td>0.214547</td>\n",
       "      <td>0.348529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052251</td>\n",
       "      <td>0.038475</td>\n",
       "      <td>0.138919</td>\n",
       "      <td>0.712895</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>0.348641</td>\n",
       "      <td>0.783866</td>\n",
       "      <td>0.088857</td>\n",
       "      <td>0.168632</td>\n",
       "      <td>0.614109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.056760</td>\n",
       "      <td>0.126251</td>\n",
       "      <td>0.321210</td>\n",
       "      <td>0.442236</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>0.033650</td>\n",
       "      <td>0.028706</td>\n",
       "      <td>0.080865</td>\n",
       "      <td>0.456556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379652</td>\n",
       "      <td>0.302195</td>\n",
       "      <td>0.350641</td>\n",
       "      <td>0.921337</td>\n",
       "      <td>0.016907</td>\n",
       "      <td>0.038035</td>\n",
       "      <td>0.495513</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.315886</td>\n",
       "      <td>0.552445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.079635</td>\n",
       "      <td>0.234730</td>\n",
       "      <td>0.465533</td>\n",
       "      <td>0.647151</td>\n",
       "      <td>0.079257</td>\n",
       "      <td>0.110309</td>\n",
       "      <td>0.111939</td>\n",
       "      <td>0.113711</td>\n",
       "      <td>0.182335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>0.175053</td>\n",
       "      <td>0.712626</td>\n",
       "      <td>0.048310</td>\n",
       "      <td>0.112784</td>\n",
       "      <td>0.644366</td>\n",
       "      <td>0.098031</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.647304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.054323</td>\n",
       "      <td>0.079785</td>\n",
       "      <td>0.234577</td>\n",
       "      <td>0.778818</td>\n",
       "      <td>0.271123</td>\n",
       "      <td>0.067847</td>\n",
       "      <td>0.059410</td>\n",
       "      <td>0.188834</td>\n",
       "      <td>0.631959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601959</td>\n",
       "      <td>0.878725</td>\n",
       "      <td>0.729526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.722535</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.197421</td>\n",
       "      <td>0.644294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.205227</td>\n",
       "      <td>0.252058</td>\n",
       "      <td>0.285241</td>\n",
       "      <td>0.444180</td>\n",
       "      <td>0.139345</td>\n",
       "      <td>0.026954</td>\n",
       "      <td>0.031798</td>\n",
       "      <td>0.041058</td>\n",
       "      <td>0.209847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704503</td>\n",
       "      <td>0.530529</td>\n",
       "      <td>0.366473</td>\n",
       "      <td>0.813157</td>\n",
       "      <td>0.243191</td>\n",
       "      <td>0.175169</td>\n",
       "      <td>0.400207</td>\n",
       "      <td>0.047214</td>\n",
       "      <td>0.361458</td>\n",
       "      <td>0.556995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_events  mean_max_dist  sd_max_dist  coef_var_max_dist  \\\n",
       "0      0.638889       0.959942     0.240231           0.050978   \n",
       "1      0.777778       0.920167     0.154030           0.026472   \n",
       "2      0.472222       0.538621     0.908983           0.457181   \n",
       "3      0.638889       0.542995     0.783069           0.389272   \n",
       "4      0.583333       0.652869     0.461581           0.186096   \n",
       "..          ...            ...          ...                ...   \n",
       "195    0.166667       0.223260     0.368141           0.383310   \n",
       "196    0.027778       0.056760     0.126251           0.321210   \n",
       "197    0.527778       0.079635     0.234730           0.465533   \n",
       "198    0.027778       0.054323     0.079785           0.234577   \n",
       "199    0.055556       0.205227     0.252058           0.285241   \n",
       "\n",
       "     slope_max_dist  decr_max_dist  max_open_vel  mean_open_vel  sd_open_vel  \\\n",
       "0          0.619832       0.194640      0.870151       0.927892     0.956073   \n",
       "1          0.656287       0.187525      0.783431       1.000000     0.665735   \n",
       "2          0.557987       0.106533      0.456361       0.460181     0.573146   \n",
       "3          0.562479       0.142985      0.482131       0.447561     0.622616   \n",
       "4          0.602020       0.151547      1.000000       0.393386     1.000000   \n",
       "..              ...            ...           ...            ...          ...   \n",
       "195        0.616676       0.096793      0.144433       0.127607     0.214547   \n",
       "196        0.442236       0.107226      0.033650       0.028706     0.080865   \n",
       "197        0.647151       0.079257      0.110309       0.111939     0.113711   \n",
       "198        0.778818       0.271123      0.067847       0.059410     0.188834   \n",
       "199        0.444180       0.139345      0.026954       0.031798     0.041058   \n",
       "\n",
       "     coef_var_open_vel  ...  mean_tap_dur  sd_tap_dur  coef_var_tap_dur  \\\n",
       "0             0.197846  ...      0.045689    0.062263          0.243113   \n",
       "1             0.094380  ...      0.024181    0.006713          0.028440   \n",
       "2             0.255551  ...      0.069597    0.036218          0.113013   \n",
       "3             0.295682  ...      0.051355    0.036783          0.133346   \n",
       "4             0.611015  ...      0.047748    0.031475          0.116283   \n",
       "..                 ...  ...           ...         ...               ...   \n",
       "195           0.348529  ...      0.052251    0.038475          0.138919   \n",
       "196           0.456556  ...      0.379652    0.302195          0.350641   \n",
       "197           0.182335  ...      0.065133    0.052355          0.175053   \n",
       "198           0.631959  ...      0.601959    0.878725          0.729526   \n",
       "199           0.209847  ...      0.704503    0.530529          0.366473   \n",
       "\n",
       "     slope_tap_dur  mean_rms    sd_rms  slope_rms   sum_rms  jerkiness  \\\n",
       "0         0.713026  0.725267  0.502424   0.582741  0.705809   0.357179   \n",
       "1         0.711860  0.798303  0.320535   0.628076  0.919098   0.239462   \n",
       "2         0.711745  0.492411  0.432710   0.575695  0.385027   0.445467   \n",
       "3         0.714702  0.483074  0.518201   0.590592  0.495385   0.406332   \n",
       "4         0.711170  0.592132  0.302044   0.612841  0.543983   0.403425   \n",
       "..             ...       ...       ...        ...       ...        ...   \n",
       "195       0.712895  0.229812  0.348641   0.783866  0.088857   0.168632   \n",
       "196       0.921337  0.016907  0.038035   0.495513  0.005550   0.315886   \n",
       "197       0.712626  0.048310  0.112784   0.644366  0.098031   0.176400   \n",
       "198       1.000000  0.012118  0.000000   0.722535  0.004910   0.197421   \n",
       "199       0.813157  0.243191  0.175169   0.400207  0.047214   0.361458   \n",
       "\n",
       "      entropy  \n",
       "0    0.648389  \n",
       "1    0.648389  \n",
       "2    0.648389  \n",
       "3    0.639671  \n",
       "4    0.646886  \n",
       "..        ...  \n",
       "195  0.614109  \n",
       "196  0.552445  \n",
       "197  0.647304  \n",
       "198  0.644294  \n",
       "199  0.556995  \n",
       "\n",
       "[200 rows x 26 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without feature selection\n",
    "feat_selector = 'none'\n",
    "X_norm = MinMaxScaler().fit_transform(X_df.iloc[:,1:]) # y = (x – min) / (max – min)\n",
    "X_df_norm = pd.DataFrame(data=X_norm, columns=X_df.iloc[:,1:].columns)\n",
    "X_df = X_df_norm\n",
    "X = X_df.values\n",
    "X_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling And Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = MinMaxScaler().fit_transform(X_df.iloc[:,1:]) # y = (x – min) / (max – min)\n",
    "# num_folds = 5\n",
    "num_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pred)\n",
    "def rfe_cv_feat_selector(X_df, model, num_folds):\n",
    "\n",
    "    # X_norm = MinMaxScaler().fit_transform(X_df.iloc[:,1:]) # y = (x – min) / (max – min)\n",
    "    \n",
    "    min_features_to_select = 1  # Min number of features to consider\n",
    "    clf = pred.select_model(model)\n",
    "    # clf = LogisticRegression()\n",
    "    cv = StratifiedKFold(num_folds)\n",
    "\n",
    "    rfecv = RFECV(\n",
    "        estimator=clf,\n",
    "        step=1,\n",
    "        cv=cv,\n",
    "        scoring=\"accuracy\",\n",
    "        min_features_to_select=min_features_to_select,\n",
    "        n_jobs=2,\n",
    "    )\n",
    "    rfecv.fit(X_norm, y)\n",
    "\n",
    "    print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "\n",
    "    selected_features = [feature for feature, selected in zip(feat_cols, rfecv.support_) if selected]\n",
    "    print(\"Selected features:\", selected_features)\n",
    "\n",
    "\n",
    "    n_scores = len(rfecv.cv_results_[\"mean_test_score\"])\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Mean test accuracy\")\n",
    "    plt.errorbar(\n",
    "        range(min_features_to_select, n_scores + min_features_to_select),\n",
    "        rfecv.cv_results_[\"mean_test_score\"],\n",
    "        yerr=rfecv.cv_results_[\"std_test_score\"],\n",
    "    )\n",
    "    plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "    plt.show()\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 5\n",
      "Selected features: ['mean_max_dist', 'slope_max_dist', 'max_close_vel', 'mean_rms', 'sum_rms']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "rfe_decisiontree_5\n"
     ]
    }
   ],
   "source": [
    "rfe_model_str = 'decisiontree'\n",
    "rfe_decision_tree =  rfe_cv_feat_selector(X_df,rfe_model_str,num_folds)\n",
    "feat_selector = f'rfe_{rfe_model_str}_{len(rfe_decision_tree)}'\n",
    "print(len(rfe_decision_tree))\n",
    "print(feat_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 25\n",
      "Selected features: ['num_events', 'mean_max_dist', 'sd_max_dist', 'coef_var_max_dist', 'slope_max_dist', 'decr_max_dist', 'max_open_vel', 'mean_open_vel', 'sd_open_vel', 'coef_var_open_vel', 'slope_open_vel', 'max_close_vel', 'mean_close_vel', 'sd_close_vel', 'coef_var_close_vel', 'slope_close_vel', 'mean_tap_dur', 'sd_tap_dur', 'coef_var_tap_dur', 'mean_rms', 'sd_rms', 'slope_rms', 'sum_rms', 'jerkiness', 'entropy']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "rfe_logit_25\n"
     ]
    }
   ],
   "source": [
    "rfe_model_str = 'logit'\n",
    "rfe_logit =  rfe_cv_feat_selector(X_df,rfe_model_str,num_folds)\n",
    "feat_selector = f'rfe_{rfe_model_str}_{num_folds}folds_{len(rfe_logit)}'\n",
    "print(len(rfe_logit))\n",
    "print(feat_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_norm = pd.DataFrame(data=X_norm, columns=X_df.iloc[:,1:].columns)\n",
    "X_df = X_df_norm[rfe_logit]\n",
    "X = X_df.values\n",
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_df_norm \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mX_norm, columns\u001b[39m=\u001b[39mX_df\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m      2\u001b[0m X_df_norm\n\u001b[0;32m      3\u001b[0m X_df \u001b[39m=\u001b[39m X_df_norm[rfe_randomforest]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_norm' is not defined"
     ]
    }
   ],
   "source": [
    "X_df_norm = pd.DataFrame(data=X_norm, columns=X_df.iloc[:,1:].columns)\n",
    "X_df_norm\n",
    "X_df = X_df_norm[rfe_randomforest]\n",
    "X_df\n",
    "X = X_df.values\n",
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "3 selected features\n"
     ]
    }
   ],
   "source": [
    "num_feats = 3\n",
    "rfe_model = 'logit'\n",
    "feat_selector = f'rfe_{rfe_model}_{num_feats}'\n",
    "X_norm = MinMaxScaler().fit_transform(X_df.iloc[:,1:]) # y = (x – min) / (max – min)\n",
    "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=num_feats, step=1, verbose=5)\n",
    "rfe_selector.fit(X_norm, y)\n",
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = X_df.iloc[:,1:].loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_feature\n",
    "X_df_norm = pd.DataFrame(data=X_norm, columns=X_df.iloc[:,1:].columns)\n",
    "X_df_norm\n",
    "X_df = X_df_norm[rfe_feature]\n",
    "X_df\n",
    "X = X_df.values\n",
    "len(X[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Matrix\n",
    "###### Feature selection based on correlation coefficients does not require scaling. Correlation is scale-invariant, which means it remains the same if all values of one or both of the variables are multiplied by a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features 'num_events' and 'sum_rms' are highly correlated (correlation coefficient = 0.745844862321298)\n",
      "Features 'mean_max_dist' and 'mean_open_vel' are highly correlated (correlation coefficient = 0.7916627915697892)\n",
      "Features 'mean_max_dist' and 'mean_close_vel' are highly correlated (correlation coefficient = 0.7928298207455187)\n",
      "Features 'mean_max_dist' and 'mean_rms' are highly correlated (correlation coefficient = 0.9172414310357759)\n",
      "Features 'mean_max_dist' and 'sum_rms' are highly correlated (correlation coefficient = 0.8732693317332934)\n",
      "Features 'slope_max_dist' and 'decr_max_dist' are highly correlated (correlation coefficient = 0.7622230555763894)\n",
      "Features 'slope_max_dist' and 'slope_rms' are highly correlated (correlation coefficient = 0.7898987474686867)\n",
      "Features 'max_open_vel' and 'mean_open_vel' are highly correlated (correlation coefficient = 0.9052636315907898)\n",
      "Features 'max_open_vel' and 'sd_open_vel' are highly correlated (correlation coefficient = 0.8592439810995275)\n",
      "Features 'max_open_vel' and 'max_close_vel' are highly correlated (correlation coefficient = 0.7404200105002625)\n",
      "Features 'max_open_vel' and 'mean_close_vel' are highly correlated (correlation coefficient = 0.7412810320258006)\n",
      "Features 'mean_open_vel' and 'max_close_vel' are highly correlated (correlation coefficient = 0.718873471836796)\n",
      "Features 'mean_open_vel' and 'mean_close_vel' are highly correlated (correlation coefficient = 0.8114962874071852)\n",
      "Features 'mean_open_vel' and 'sum_rms' are highly correlated (correlation coefficient = 0.8353468836720918)\n",
      "Features 'coef_var_open_vel' and 'coef_var_close_vel' are highly correlated (correlation coefficient = 0.7486837170929274)\n",
      "Features 'max_close_vel' and 'mean_close_vel' are highly correlated (correlation coefficient = 0.8793549838745969)\n",
      "Features 'max_close_vel' and 'sd_close_vel' are highly correlated (correlation coefficient = 0.8365454136353409)\n",
      "Features 'mean_close_vel' and 'sum_rms' are highly correlated (correlation coefficient = 0.8428725718142953)\n",
      "Features 'mean_tap_dur' and 'sd_tap_dur' are highly correlated (correlation coefficient = 0.7086717167929198)\n",
      "Features 'sd_tap_dur' and 'coef_var_tap_dur' are highly correlated (correlation coefficient = 0.9208940223505587)\n",
      "Features 'mean_rms' and 'sum_rms' are highly correlated (correlation coefficient = 0.8175474386859671)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(statis)\n",
    "feat_selector = 'corr_matrix'\n",
    "correlation_matrix = statis.plot_correlation_matrix(X_df, task, feat_file, to_save=False)\n",
    "# define threshold for redundant features\n",
    "threshold = 0.7\n",
    "\n",
    "# np.where() gives a tuple with 2 arrays corresponding to (row, col), respectively\n",
    "highly_corr_fts = np.where(\n",
    "    np.logical_and(correlation_matrix > threshold, correlation_matrix != 1)\n",
    "    )\n",
    "\n",
    "# the abs function takes the absolute value of the correlation matrix, so any value \n",
    "# above 0.7, whether it's positive or negative, will be considered\n",
    "# # highly_corr_fts = np.where(\n",
    "# #     np.logical_and(abs(corr_matrix) > threshold, corr_matrix != 1)\n",
    "# # )\n",
    "\n",
    "corr_pairs = list(zip(highly_corr_fts[0], highly_corr_fts[1]))\n",
    "\n",
    "pairs_name = []\n",
    "for pair in corr_pairs:\n",
    "    if pair[0] < pair[1]:\n",
    "        print(f\"Features '{correlation_matrix.columns[pair[0]]}' and '{correlation_matrix.columns[pair[1]]}' are highly correlated (correlation coefficient = {correlation_matrix.iloc[pair]})\")\n",
    "        pairs_name.append((correlation_matrix.columns[pair[0]],correlation_matrix.columns[pair[1]]))\n",
    "\n",
    "feat_to_remove = set([pairs_name[i][1] for i in np.arange(len(pairs_name))])\n",
    "feat_to_remove\n",
    "\n",
    "# drop redundant features from X_df dataframe, leave out file name column and get X array\n",
    "X = X_df.iloc[:,1:].drop(columns = feat_to_remove).values\n",
    "X.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data splitting, create training and test data\n",
    "### Train Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:107: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = 2 * (prec * rec) / (prec + rec)\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:107: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = 2 * (prec * rec) / (prec + rec)\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n",
      "c:\\Users\\madal\\Projects\\Thesis\\ultraleap_analysis\\code\\sig_processing\\predict.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  prec = np.diag(cm) / np.sum(cm, axis=0)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pred)\n",
    "ls_model = ['neuralnet','linearsvm','nonlinearsvm', 'logit','randomforest','kneighbors','gaussiannaivebayes']\n",
    "ls_binary = [True,False]\n",
    "ls_cvlabel = ['skf', 'logocv']\n",
    "# ls_cvlabel = ['skf', 'logocv', 'loocv']\n",
    "\n",
    "for model in ls_model: \n",
    "    for cl in ls_binary:\n",
    "        for cv in ls_cvlabel:\n",
    "            if cv=='logocv':\n",
    "                group_int=group_int\n",
    "            pred.classifier(task, feat_selector, feat_file, cv, model, X, y, binary = cl, group_int=group_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Tables w/ Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madal\\AppData\\Local\\Temp\\ipykernel_41024\\598559144.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(read_metrics)\n",
      "C:\\Users\\madal\\AppData\\Local\\Temp\\ipykernel_41024\\598559144.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(read_metrics)\n",
      "C:\\Users\\madal\\AppData\\Local\\Temp\\ipykernel_41024\\598559144.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(read_metrics)\n",
      "C:\\Users\\madal\\AppData\\Local\\Temp\\ipykernel_41024\\598559144.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(read_metrics)\n",
      "C:\\Users\\madal\\AppData\\Local\\Temp\\ipykernel_41024\\598559144.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(read_metrics)\n",
      "C:\\Users\\madal\\AppData\\Local\\Temp\\ipykernel_41024\\598559144.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(read_metrics)\n",
      "C:\\Users\\madal\\AppData\\Local\\Temp\\ipykernel_41024\\598559144.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(read_metrics)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neuralnet</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.485149</td>\n",
       "      <td>0.692641</td>\n",
       "      <td>0.579882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linearsvm</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.582609</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.620370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonlinearsvm</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.358621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit</th>\n",
       "      <td>0.705</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.700508</td>\n",
       "      <td>0.709360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest</th>\n",
       "      <td>0.665</td>\n",
       "      <td>0.650943</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.673171</td>\n",
       "      <td>0.656410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kneighbors</th>\n",
       "      <td>0.480</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.405941</td>\n",
       "      <td>0.514019</td>\n",
       "      <td>0.440860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaussiannaivebayes</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.594406</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.425743</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.544304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy  Precision_0  Precision_1  Recall_0  Recall_1  \\\n",
       "neuralnet              0.645     0.606061     0.720588  0.808081  0.485149   \n",
       "linearsvm              0.590     0.600000     0.582609  0.515152  0.663366   \n",
       "nonlinearsvm           0.535     0.519231     0.590909  0.818182  0.257426   \n",
       "logit                  0.705     0.704082     0.705882  0.696970  0.712871   \n",
       "randomforest           0.665     0.650943     0.680851  0.696970  0.633663   \n",
       "kneighbors             0.480     0.478261     0.482353  0.555556  0.405941   \n",
       "gaussiannaivebayes     0.640     0.594406     0.754386  0.858586  0.425743   \n",
       "\n",
       "                        F1_0      F1_1  \n",
       "neuralnet           0.692641  0.579882  \n",
       "linearsvm           0.554348  0.620370  \n",
       "nonlinearsvm        0.635294  0.358621  \n",
       "logit               0.700508  0.709360  \n",
       "randomforest        0.673171  0.656410  \n",
       "kneighbors          0.514019  0.440860  \n",
       "gaussiannaivebayes  0.702479  0.544304  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = 'ft'\n",
    "ls_model = ['neuralnet','linearsvm','nonlinearsvm', 'logit','randomforest','kneighbors','gaussiannaivebayes']\n",
    "# ls_class = ['binary', 'multiclass']\n",
    "cl = 'binary'\n",
    "cvlabel = 'logocv'\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for model in ls_model:\n",
    "    # for cl in ls_class:\n",
    "    read_metrics = pd.read_excel(os.path.join(repo_path,'modelling', feat_file, task, feat_selector, cl, cvlabel, model, f'{task}_{feat_selector}_{cl}_{cvlabel}_{model}_metrics.xlsx'), index_col=0)\n",
    "    read_metrics = read_metrics.transpose()\n",
    "    read_metrics['model'] = model\n",
    "\n",
    "    all_data = all_data.append(read_metrics)\n",
    "    \n",
    "\n",
    "all_data.set_index('model', inplace=True)\n",
    "all_data.index.name = None\n",
    "\n",
    "path_metrics_total = os.path.join(repo_path, 'modelling', feat_file, task, feat_selector, cl, cvlabel)\n",
    "if not os.path.exists(path_metrics_total):\n",
    "    os.makedirs(path_metrics_total)\n",
    "all_data.to_excel(os.path.join(path_metrics_total, f'{task}_{feat_selector}_{cl}_{cvlabel}_metrics_total.xlsx'))\n",
    "all_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming you have X (input features), y (target variable), and groups (group labels)\n",
    "# Replace them with your own data\n",
    "\n",
    "# Initialize the LeaveOneGroupOut cross-validator\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store true labels and predicted probabilities for all folds\n",
    "true_labels = []\n",
    "pred_probs = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in logo.split(X, y, groups):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit your classifier (e.g., Logistic Regression) on the training data\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the probabilities for the test data\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Store true labels and predicted probabilities for this fold\n",
    "    true_labels.extend(y_test)\n",
    "    pred_probs.extend(y_pred_prob)\n",
    "\n",
    "# Compute the false positive rate (FPR), true positive rate (TPR), and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, pred_probs)\n",
    "\n",
    "# Compute the AUC score\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Random guess line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultraleap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
